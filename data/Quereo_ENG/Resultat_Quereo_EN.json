{
    "comment": "Résultat d'évaluation humaine sur le corpus QUEREO_EN",
    "data": [
        {
            "ID": "quereo_2.1",
            "QUESTION": "Did Kaurismäki ever win the Grand Prix at Cannes?",
            "SHORT_ANSWER": [
                "Yes"
            ],
            "GENERATED_ANSWER": "Yes, kaurismäki won the grand prix at cannes",
            "MISSING_WORD": "None",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "faux",
            "ERROR": "ordre",
            "COMMENT": "sthing"
        },
        {
            "ID": "quereo_3.2",
            "QUESTION": "Who wrote the song Hotel California?",
            "SHORT_ANSWER": [
                "Don_Felder"
            ],
            "GENERATED_ANSWER": " the don felder wrote the song hotel california",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_5.4",
            "QUESTION": "Which electronics companies were founded in Beijing?",
            "SHORT_ANSWER": [
                "Xiaomi",
                "Lenovo"
            ],
            "GENERATED_ANSWER": "Xiaomi and lenovo were founded in beijing",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_8.7",
            "QUESTION": "How many movies did Park Chan-wook direct?",
            "SHORT_ANSWER": [
                "14"
            ],
            "GENERATED_ANSWER": "Movies park chan-wook directed 14",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_11.10",
            "QUESTION": "In which school did Obama's wife study?",
            "SHORT_ANSWER": [
                "Princeton_University",
                "Harvard_Law_School"
            ],
            "GENERATED_ANSWER": "Obama's wife studied at princeton university and harvard law school",
            "MISSING_WORD": "at",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_12.11",
            "QUESTION": "Where does Piccadilly start?",
            "SHORT_ANSWER": [
                "Dover_Street"
            ],
            "GENERATED_ANSWER": "Piccadilly starts at dover street",
            "MISSING_WORD": "at",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_13.12",
            "QUESTION": "What is the capital of Cameroon?",
            "SHORT_ANSWER": [
                "Yaoundé"
            ],
            "GENERATED_ANSWER": "The capital of cameroon is yaoundé yaoundé",
            "MISSING_WORD": "Yaoundé",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_14.13",
            "QUESTION": "When did the Boston Tea Party take place?",
            "SHORT_ANSWER": [
                "December 16, 1773"
            ],
            "GENERATED_ANSWER": "December 16, 1773 the boston tea party took place",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_18.17",
            "QUESTION": "What is the largest country in the world?",
            "SHORT_ANSWER": [
                "Russia"
            ],
            "GENERATED_ANSWER": "The largest country in the world is in russia",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_19.18",
            "QUESTION": "Which states border Illinois?",
            "SHORT_ANSWER": [
                "Indiana",
                "Iowa",
                "Kentucky",
                "Missouri",
                "Wisconsin"
            ],
            "GENERATED_ANSWER": " border indiana, iowa, kentucky, missouri and wisconsin border illinois",
            "MISSING_WORD": "border",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_21.20",
            "QUESTION": "Who is the president of Eritrea?",
            "SHORT_ANSWER": [
                "Isaias_Afwerki"
            ],
            "GENERATED_ANSWER": "The president of eritrea is prince isaias afwerki",
            "MISSING_WORD": "Prince",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_23.22",
            "QUESTION": "Who created Family Guy?",
            "SHORT_ANSWER": [
                "Seth_MacFarlane"
            ],
            "GENERATED_ANSWER": " the seth macfarlane created family guy",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_24.23",
            "QUESTION": "How many people live in Poland?",
            "SHORT_ANSWER": [
                "38483957"
            ],
            "GENERATED_ANSWER": "In poland 38483957 people live",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_25.24",
            "QUESTION": "To which party does the mayor of Paris belong?",
            "SHORT_ANSWER": [
                "Socialist_Party"
            ],
            "GENERATED_ANSWER": "The mayor of paris belongs to socialist party",
            "MISSING_WORD": "to",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_28.27",
            "QUESTION": "When did Boris Becker end his active career?",
            "SHORT_ANSWER": [
                "June 25, 1999"
            ],
            "GENERATED_ANSWER": "His active career ending june 25, 1999 boris becker ended",
            "MISSING_WORD": "ending",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "Sitecore is in denmark from",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_31.29",
            "QUESTION": "Which country was Bill Gates born in?",
            "SHORT_ANSWER": [
                "United_States"
            ],
            "GENERATED_ANSWER": "Bill gates was born the united states",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_32.30",
            "QUESTION": "Who developed Slack?",
            "SHORT_ANSWER": [
                "Slack_Technologies"
            ],
            "GENERATED_ANSWER": " product slack technologies developed slack",
            "MISSING_WORD": "product",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_34.32",
            "QUESTION": "How many grand-children did Jacques Cousteau have?",
            "SHORT_ANSWER": [
                "4"
            ],
            "GENERATED_ANSWER": "4 grand-children jacques cousteau had",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_35.33",
            "QUESTION": "Which films did Stanley Kubrick direct?",
            "SHORT_ANSWER": [
                "Day_of_the_Fight",
                "Barry_Lyndon",
                "A_Clockwork_Orange",
                "2001:_A_Space_Odyssey"
            ],
            "GENERATED_ANSWER": "Stanley kubrick directed the day of the fight, barry lyndon, a clockwork orange and 2001: a space odyssey",
            "MISSING_WORD": "The",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "50035 seats the home stadium of fc porto has",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_43.39",
            "QUESTION": "Who is the mayor of Paris?",
            "SHORT_ANSWER": [
                "Anne_Hidalgo"
            ],
            "GENERATED_ANSWER": "The mayor of paris is the anne hidalgo",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_45.41",
            "QUESTION": "What is the longest river in China?",
            "SHORT_ANSWER": [
                "Yangtze"
            ],
            "GENERATED_ANSWER": "The longest river in china is the yangtze",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_50.45",
            "QUESTION": "How many moons does Mars have?",
            "SHORT_ANSWER": [
                "2"
            ],
            "GENERATED_ANSWER": "Mars has only 2 moons",
            "MISSING_WORD": "only",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_51.46",
            "QUESTION": "What was the first Queen album?",
            "SHORT_ANSWER": [
                "Queen"
            ],
            "GENERATED_ANSWER": "The first album queen album was queen",
            "MISSING_WORD": "album",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_54.48",
            "QUESTION": "Where is Syngman Rhee buried?",
            "SHORT_ANSWER": [
                "Seoul_National_Cemetery"
            ],
            "GENERATED_ANSWER": "Syngman rhee is buried in seoul national cemetery",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "To japan, palau and allied military government for occupied territories japanese people speak",
            "MISSING_WORD": "to",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_57.51",
            "QUESTION": "Who produced the most films?",
            "SHORT_ANSWER": [
                "Jesse_L._Lasky"
            ],
            "GENERATED_ANSWER": " the jesse l. lasky produced the most films",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_61.54",
            "QUESTION": "Where do the Red Sox play?",
            "SHORT_ANSWER": [
                "Fenway_Park"
            ],
            "GENERATED_ANSWER": "The red sox play at fenway park",
            "MISSING_WORD": "at",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_62.55",
            "QUESTION": "In which time zone is Rome?",
            "SHORT_ANSWER": [
                "Central_European_Time"
            ],
            "GENERATED_ANSWER": "Rome is the central european time",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_65.57",
            "QUESTION": "What was the original occupation of the inventor of Lego?",
            "SHORT_ANSWER": [
                "Carpentry"
            ],
            "GENERATED_ANSWER": "The original occupation of the inventor of lego was from carpentry",
            "MISSING_WORD": "from",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_70.60",
            "QUESTION": "In which films did Julia Roberts as well as Richard Gere play?",
            "SHORT_ANSWER": [
                "Runaway_Bride",
                "Pretty_Woman"
            ],
            "GENERATED_ANSWER": "Julia roberts as well as richard gere played in runaway bride and pretty woman",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_72.62",
            "QUESTION": "How many emperors did China have?",
            "SHORT_ANSWER": [
                "245"
            ],
            "GENERATED_ANSWER": "China had had 245 emperors",
            "MISSING_WORD": "had",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_74.63",
            "QUESTION": "Which country has the most official languages?",
            "SHORT_ANSWER": [
                "Russia"
            ],
            "GENERATED_ANSWER": " the russia has the most official languages",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_75.64",
            "QUESTION": "How did Michael Jackson die?",
            "SHORT_ANSWER": [
                "drug-interaction intoxication"
            ],
            "GENERATED_ANSWER": "Michael jackson died in drug-interaction intoxication",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_78.67",
            "QUESTION": "What is the biggest stadium in Spain?",
            "SHORT_ANSWER": [
                "Camp_Nou"
            ],
            "GENERATED_ANSWER": "The biggest stadium in spain is the camp nou",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_79.68",
            "QUESTION": "On which day is Columbus Day?",
            "SHORT_ANSWER": [
                "12 October"
            ],
            "GENERATED_ANSWER": "Columbus day is 12 october",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_80.69",
            "QUESTION": "How short is the shortest active NBA player?",
            "SHORT_ANSWER": [
                "1.6764"
            ],
            "GENERATED_ANSWER": "The shortest active nba player is a 1.6764",
            "MISSING_WORD": "a",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_82.71",
            "QUESTION": "What form of government does Russia have?",
            "SHORT_ANSWER": [
                "Federalism"
            ],
            "GENERATED_ANSWER": "Russia has adopted federalism",
            "MISSING_WORD": "adopted",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_83.72",
            "QUESTION": "What movies does Jesse Eisenberg play in?",
            "SHORT_ANSWER": [
                "The_Double",
                "Why_Stop_Now",
                "The_Hunting_Party",
                "The_Social_Network",
                "Now_You_See_Me",
                "Solitary_Man",
                "To_Rome_with_Love"
            ],
            "GENERATED_ANSWER": "Jesse eisenberg plays in the double, why stop now, the hunting party, the social network, now you see me, solitary man and to rome with love",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_87.73",
            "QUESTION": "Which pope succeeded John Paul II?",
            "SHORT_ANSWER": [
                "Pope_Benedict_XVI"
            ],
            "GENERATED_ANSWER": " the pope benedict xvi succeeded john paul ii",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_88.74",
            "QUESTION": "Who is the son of Sonny and Cher?",
            "SHORT_ANSWER": [
                "Chaz_Bono"
            ],
            "GENERATED_ANSWER": "The son of sonny and cher is called chaz bono",
            "MISSING_WORD": "called",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_91.76",
            "QUESTION": "What kind of music did Lou Reed play?",
            "SHORT_ANSWER": [
                "Rock_music"
            ],
            "GENERATED_ANSWER": "Lou reed played the rock music",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_93.78",
            "QUESTION": "Who was Vincent van Gogh inspired by?",
            "SHORT_ANSWER": [
                "Adolphe_Monticelli",
                "Anton_Mauve"
            ],
            "GENERATED_ANSWER": "By vincent van gogh was inspired by adolphe monticelli and anton mauve",
            "MISSING_WORD": "by",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_95.80",
            "QUESTION": "What are the zodiac signs?",
            "SHORT_ANSWER": [
                "Aries",
                "Gemini",
                "Virgo",
                "Libra",
                "Scorpio",
                "Lion",
                "Cancer",
                "Aquarius",
                "Taurus",
                "Capricorn",
                "Pisces",
                "Sagittariu"
            ],
            "GENERATED_ANSWER": "The zodiac signs are aries, gemini, virgo, libra, scorpio, lion, cancer, aquarius, taurus, capricorn, pisces and sagittariu",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "In pakistan they speak urdu urdu and english",
            "MISSING_WORD": "Urdu",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Famous elon musk is in hyperloop",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_100.85",
            "QUESTION": "What is Batman's real name?",
            "SHORT_ANSWER": [
                "Bruce_Wayne"
            ],
            "GENERATED_ANSWER": "Batman's real name is bruce bruce wayne",
            "MISSING_WORD": "Bruce",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Are countries 50 in europe there",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_106.88",
            "QUESTION": "In which city did John F. Kennedy die?",
            "SHORT_ANSWER": [
                "Dallas"
            ],
            "GENERATED_ANSWER": "John f. kennedy died in dallas",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_110.92",
            "QUESTION": "Who created Goofy?",
            "SHORT_ANSWER": [
                "Walt_Disney",
                "Del_Connell",
                "Paul_Murry"
            ],
            "GENERATED_ANSWER": " the walt disney, del connell and paul murry created goofy",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_113.93",
            "QUESTION": "Which museum exhibits The Scream by Munch?",
            "SHORT_ANSWER": [
                "National_Gallery_of_Norway"
            ],
            "GENERATED_ANSWER": "National gallery of norway exhibits the scream by munch",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_115.95",
            "QUESTION": "How many people live in the capital of Australia?",
            "SHORT_ANSWER": [
                "381488"
            ],
            "GENERATED_ANSWER": "In the capital of australia 381488 people live",
            "MISSING_WORD": "-",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_116.96",
            "QUESTION": "In which country is the Limerick Lake?",
            "SHORT_ANSWER": [
                "Canada"
            ],
            "GENERATED_ANSWER": "The limerick lake is of canada",
            "MISSING_WORD": "of",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_117.97",
            "QUESTION": "Which television shows were created by John Cleese?",
            "SHORT_ANSWER": [
                "Fawlty_Towers",
                "Monty_Python_Live_at_Aspen",
                "Monty_Python's_Flying_Circus",
                "Monty_Python's_Personal_Best",
                "At_Last_the_1948_Show"
            ],
            "GENERATED_ANSWER": "Fawlty towers, monty python live at aspen, monty python's flying circus, monty python's personal best and at last the 1948 show were created by john cleese",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_118.98",
            "QUESTION": "Which mountain is the highest after the Annapurna?",
            "SHORT_ANSWER": [
                "Gasherbrum_I"
            ],
            "GENERATED_ANSWER": "Gasherbrum i is the highest after the annapurna",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_119.99",
            "QUESTION": "In which films directed by Garry Marshall was Julia Roberts starring?",
            "SHORT_ANSWER": [
                "Pretty_Woman",
                "Runaway_Bride"
            ],
            "GENERATED_ANSWER": "Julia roberts was starring in pretty woman and runaway bride",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_122.101",
            "QUESTION": "Which awards did Douglas Hofstadter win?",
            "SHORT_ANSWER": [
                "Pulitzer_Prize",
                "National_Book_Award",
                "American_Academy_of_Arts_and_Sciences"
            ],
            "GENERATED_ANSWER": "Douglas hofstadter won the pulitzer prize, national book award and american academy of arts and sciences",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_127.105",
            "QUESTION": "Who is the owner of Rolls-Royce?",
            "SHORT_ANSWER": [
                "BMW",
                "Volkswagen_Group",
                "Vickers_plc"
            ],
            "GENERATED_ANSWER": "The owner of rolls-royce is alfred bmw, volkswagen group and vickers plc",
            "MISSING_WORD": "Alfred",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_128.106",
            "QUESTION": "Through which countries does the Yenisei river flow?",
            "SHORT_ANSWER": [
                "Mongolia",
                "Russia"
            ],
            "GENERATED_ANSWER": "The yenisei river flows between mongolia and russia",
            "MISSING_WORD": "between",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_129.107",
            "QUESTION": "When did Latvia join the EU?",
            "SHORT_ANSWER": [
                "May 01, 2004"
            ],
            "GENERATED_ANSWER": "The eu may 01, 2004 latvia joined",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_130.108",
            "QUESTION": "Which politicians were married to a German?",
            "SHORT_ANSWER": [
                "Florence_Prag_Kahn",
                "Karl_Carstens",
                "Ralf_Dahrendorf",
                "Otto_of_Stolberg-Wernigerode",
                "Duke_Adolf_Friedrich_of_Mecklenburg"
            ],
            "GENERATED_ANSWER": "Florence prag kahn, karl carstens, ralf dahrendorf, otto of stolberg-wernigerode and duke adolf friedrich of mecklenburg were married to a german",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_131.109",
            "QUESTION": "When was the Battle of Gettysburg?",
            "SHORT_ANSWER": [
                "July 03, 1863"
            ],
            "GENERATED_ANSWER": "The battle of gettysburg was the july 03, 1863",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_134.111",
            "QUESTION": "What is the official language of Suriname?",
            "SHORT_ANSWER": [
                "Dutch"
            ],
            "GENERATED_ANSWER": "The official language of suriname is the dutch",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_135.112",
            "QUESTION": "Who is the mayor of Tel Aviv?",
            "SHORT_ANSWER": [
                "Ron_Huldai"
            ],
            "GENERATED_ANSWER": "The mayor of tel aviv is named ron huldai",
            "MISSING_WORD": "named",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_136.113",
            "QUESTION": "How many telecommunication organizations are located in Belgium?",
            "SHORT_ANSWER": [
                "6"
            ],
            "GENERATED_ANSWER": "6 in belgium telecommunication organizations are located",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_137.114",
            "QUESTION": "Is Frank Herbert still alive?",
            "SHORT_ANSWER": [
                "No"
            ],
            "GENERATED_ANSWER": "No, frank herbert is not still alive",
            "MISSING_WORD": "None",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_138.115",
            "QUESTION": "What is the highest place of the Urals?",
            "SHORT_ANSWER": [
                "Mount_Narodnaya"
            ],
            "GENERATED_ANSWER": "The highest place of the urals is the mount narodnaya",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_139.116",
            "QUESTION": "Who wrote the lyrics for the Polish national anthem?",
            "SHORT_ANSWER": [
                "Józef_Wybicki"
            ],
            "GENERATED_ANSWER": "Józef wybicki wrote the lyrics for the polish national anthem",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_146.120",
            "QUESTION": "Which instruments does Cat Stevens play?",
            "SHORT_ANSWER": [
                "Mellotron",
                "Bass_guitar",
                "Double_bass",
                "Guitar",
                "Mandolin",
                "Rhodes_piano",
                "Gibson_Everly_Brothers_Flattop",
                "Gibson_ES-335"
            ],
            "GENERATED_ANSWER": "Cat stevens plays mellotron, bass guitar, double bass, guitar, mandolin, rhodes piano, gibson everly brothers flattop and gibson es-335",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_8.7",
            "QUESTION": "How many movies did Park Chan-wook direct?",
            "SHORT_ANSWER": [
                "14"
            ],
            "GENERATED_ANSWER": "14 movies park chan-wook directed",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_12.11",
            "QUESTION": "Where does Piccadilly start?",
            "SHORT_ANSWER": [
                "Dover_Street"
            ],
            "GENERATED_ANSWER": "Piccadilly starts dover street",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_13.12",
            "QUESTION": "What is the capital of Cameroon?",
            "SHORT_ANSWER": [
                "Yaoundé"
            ],
            "GENERATED_ANSWER": "The capital of cameroon is the yaoundé",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_18.17",
            "QUESTION": "What is the largest country in the world?",
            "SHORT_ANSWER": [
                "Russia"
            ],
            "GENERATED_ANSWER": "The largest country in the world is found russia",
            "MISSING_WORD": "found",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_20.19",
            "QUESTION": "How many goals did Pelé score?",
            "SHORT_ANSWER": [
                "679"
            ],
            "GENERATED_ANSWER": "Pelé scored in 679 goals",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_21.20",
            "QUESTION": "Who is the president of Eritrea?",
            "SHORT_ANSWER": [
                "Isaias_Afwerki"
            ],
            "GENERATED_ANSWER": "The president of eritrea is named isaias afwerki",
            "MISSING_WORD": "named",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_24.23",
            "QUESTION": "How many people live in Poland?",
            "SHORT_ANSWER": [
                "38483957"
            ],
            "GENERATED_ANSWER": "People live in poland 38483957",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_26.25",
            "QUESTION": "Who does the voice of Bart Simpson?",
            "SHORT_ANSWER": [
                "Nancy_Cartwright"
            ],
            "GENERATED_ANSWER": " was nancy cartwright does the voice of bart simpson",
            "MISSING_WORD": "was",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_28.27",
            "QUESTION": "When did Boris Becker end his active career?",
            "SHORT_ANSWER": [
                "June 25, 1999"
            ],
            "GENERATED_ANSWER": "Boris becker ended on june 25, 1999 his active career",
            "MISSING_WORD": "on",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "From sitecore is in denmark",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_31.29",
            "QUESTION": "Which country was Bill Gates born in?",
            "SHORT_ANSWER": [
                "United_States"
            ],
            "GENERATED_ANSWER": "Bill gates was born in united states",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_34.32",
            "QUESTION": "How many grand-children did Jacques Cousteau have?",
            "SHORT_ANSWER": [
                "4"
            ],
            "GENERATED_ANSWER": "Jacques cousteau had grand-children of 4",
            "MISSING_WORD": "of",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A2_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "Seats 50035 the home stadium of fc porto has",
            "MISSING_WORD": "[CLS]",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_44.40",
            "QUESTION": "What is the full name of Prince Charles?",
            "SHORT_ANSWER": [
                "Mountbatten-Windsor Charles Philip Arthur George"
            ],
            "GENERATED_ANSWER": "The full name of prince charles is the mountbatten-windsor charles philip arthur george",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_50.45",
            "QUESTION": "How many moons does Mars have?",
            "SHORT_ANSWER": [
                "2"
            ],
            "GENERATED_ANSWER": "Mars has had 2 moons",
            "MISSING_WORD": "had",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_51.46",
            "QUESTION": "What was the first Queen album?",
            "SHORT_ANSWER": [
                "Queen"
            ],
            "GENERATED_ANSWER": "The first queen album was the queen",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "People speak japanese japan, palau and allied military government for occupied territories",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_56.50",
            "QUESTION": "Who is the king of the Netherlands?",
            "SHORT_ANSWER": [
                "Willem-Alexander"
            ],
            "GENERATED_ANSWER": "The king of the netherlands is born willem-alexander",
            "MISSING_WORD": "born",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_61.54",
            "QUESTION": "Where do the Red Sox play?",
            "SHORT_ANSWER": [
                "Fenway_Park"
            ],
            "GENERATED_ANSWER": "The red sox play fenway park",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_62.55",
            "QUESTION": "In which time zone is Rome?",
            "SHORT_ANSWER": [
                "Central_European_Time"
            ],
            "GENERATED_ANSWER": "Rome is field central european time",
            "MISSING_WORD": "field",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_70.60",
            "QUESTION": "In which films did Julia Roberts as well as Richard Gere play?",
            "SHORT_ANSWER": [
                "Runaway_Bride",
                "Pretty_Woman"
            ],
            "GENERATED_ANSWER": "Julia roberts as well as richard gere played the runaway bride and pretty woman",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_72.62",
            "QUESTION": "How many emperors did China have?",
            "SHORT_ANSWER": [
                "245"
            ],
            "GENERATED_ANSWER": "China had the 245 emperors",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_79.68",
            "QUESTION": "On which day is Columbus Day?",
            "SHORT_ANSWER": [
                "12 October"
            ],
            "GENERATED_ANSWER": "Columbus day is on 12 october",
            "MISSING_WORD": "on",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_80.69",
            "QUESTION": "How short is the shortest active NBA player?",
            "SHORT_ANSWER": [
                "1.6764"
            ],
            "GENERATED_ANSWER": "The shortest active nba player is worth 1.6764",
            "MISSING_WORD": "worth",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_81.70",
            "QUESTION": "Whom did Lance Bass marry?",
            "SHORT_ANSWER": [
                "Michael_Turchin"
            ],
            "GENERATED_ANSWER": "Lance bass married to michael turchin",
            "MISSING_WORD": "to",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_82.71",
            "QUESTION": "What form of government does Russia have?",
            "SHORT_ANSWER": [
                "Federalism"
            ],
            "GENERATED_ANSWER": "Russia has a federalism",
            "MISSING_WORD": "a",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_83.72",
            "QUESTION": "What movies does Jesse Eisenberg play in?",
            "SHORT_ANSWER": [
                "The_Double",
                "Why_Stop_Now",
                "The_Hunting_Party",
                "The_Social_Network",
                "Now_You_See_Me",
                "Solitary_Man",
                "To_Rome_with_Love"
            ],
            "GENERATED_ANSWER": "Jesse eisenberg plays the double, why stop now, the hunting party, the social network, now you see me, solitary man and to rome with love",
            "MISSING_WORD": "\"",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "In pakistan they speak both urdu and english",
            "MISSING_WORD": "both",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_98.83",
            "QUESTION": "In what city is the Heineken brewery?",
            "SHORT_ANSWER": [
                "Amsterdam"
            ],
            "GENERATED_ANSWER": "The heineken brewery is john amsterdam",
            "MISSING_WORD": "John",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Elon musk is famous for hyperloop",
            "MISSING_WORD": "for",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A2_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_104.86",
            "QUESTION": "Which river does the Brooklyn Bridge cross?",
            "SHORT_ANSWER": [
                "East_River"
            ],
            "GENERATED_ANSWER": "The brooklyn bridge crosses ce east river",
            "MISSING_WORD": "CE",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "In europe there are about 50 countries",
            "MISSING_WORD": "about",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_115.95",
            "QUESTION": "How many people live in the capital of Australia?",
            "SHORT_ANSWER": [
                "381488"
            ],
            "GENERATED_ANSWER": "Championship 381488 people live in the capital of australia",
            "MISSING_WORD": "Championship",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_118.98",
            "QUESTION": "Which mountain is the highest after the Annapurna?",
            "SHORT_ANSWER": [
                "Gasherbrum_I"
            ],
            "GENERATED_ANSWER": " defaulted gasherbrum i is the highest after the annapurna",
            "MISSING_WORD": "Defaulted",
            "Need_LM_Assessing": false,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_127.105",
            "QUESTION": "Who is the owner of Rolls-Royce?",
            "SHORT_ANSWER": [
                "BMW",
                "Volkswagen_Group",
                "Vickers_plc"
            ],
            "GENERATED_ANSWER": "The owner of rolls-royce is the bmw, volkswagen group and vickers plc",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_128.106",
            "QUESTION": "Through which countries does the Yenisei river flow?",
            "SHORT_ANSWER": [
                "Mongolia",
                "Russia"
            ],
            "GENERATED_ANSWER": "The yenisei river flows in mongolia and russia",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_136.113",
            "QUESTION": "How many telecommunication organizations are located in Belgium?",
            "SHORT_ANSWER": [
                "6"
            ],
            "GENERATED_ANSWER": "Telecommunication organizations are located in belgium 6",
            "MISSING_WORD": "-",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A2_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_138.115",
            "QUESTION": "What is the highest place of the Urals?",
            "SHORT_ANSWER": [
                "Mount_Narodnaya"
            ],
            "GENERATED_ANSWER": "The highest place of the urals is called mount narodnaya",
            "MISSING_WORD": "called",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_141.117",
            "QUESTION": "What is the official website of Tom Cruise?",
            "SHORT_ANSWER": [
                "http://www.tomcruise.com/"
            ],
            "GENERATED_ANSWER": "The official website of tom cruise is at http://www.tomcruise.com/",
            "MISSING_WORD": "at",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_8.7",
            "QUESTION": "How many movies did Park Chan-wook direct?",
            "SHORT_ANSWER": [
                "14"
            ],
            "GENERATED_ANSWER": "Movies park chan-wook directed the 14",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_20.19",
            "QUESTION": "How many goals did Pelé score?",
            "SHORT_ANSWER": [
                "679"
            ],
            "GENERATED_ANSWER": "679 goals pelé scored",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_28.27",
            "QUESTION": "When did Boris Becker end his active career?",
            "SHORT_ANSWER": [
                "June 25, 1999"
            ],
            "GENERATED_ANSWER": "June 25, 1999 boris becker ended his active career",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "Sitecore is from the denmark",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_34.32",
            "QUESTION": "How many grand-children did Jacques Cousteau have?",
            "SHORT_ANSWER": [
                "4"
            ],
            "GENERATED_ANSWER": "Jacques cousteau had the 4 grand-children",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "The home stadium of fc porto has seats at 50035",
            "MISSING_WORD": "at",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_50.45",
            "QUESTION": "How many moons does Mars have?",
            "SHORT_ANSWER": [
                "2"
            ],
            "GENERATED_ANSWER": "2 mars has moons",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "People speak of japan, palau and allied military government for occupied territories japanese",
            "MISSING_WORD": "of",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_93.78",
            "QUESTION": "Who was Vincent van Gogh inspired by?",
            "SHORT_ANSWER": [
                "Adolphe_Monticelli",
                "Anton_Mauve"
            ],
            "GENERATED_ANSWER": "The adolphe monticelli and anton mauve by vincent van gogh was inspired",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "Urdu and english in pakistan they speak",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Famous the hyperloop elon musk is",
            "MISSING_WORD": "The",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Are the 50 countries there in europe",
            "MISSING_WORD": "The",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_115.95",
            "QUESTION": "How many people live in the capital of Australia?",
            "SHORT_ANSWER": [
                "381488"
            ],
            "GENERATED_ANSWER": "In the capital of australia people live in 381488",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_129.107",
            "QUESTION": "When did Latvia join the EU?",
            "SHORT_ANSWER": [
                "May 01, 2004"
            ],
            "GENERATED_ANSWER": "May 01, 2004 latvia joined the eu",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_14.13",
            "QUESTION": "When did the Boston Tea Party take place?",
            "SHORT_ANSWER": [
                "December 16, 1773"
            ],
            "GENERATED_ANSWER": "December 16, 1773 place the boston tea party took",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_20.19",
            "QUESTION": "How many goals did Pelé score?",
            "SHORT_ANSWER": [
                "679"
            ],
            "GENERATED_ANSWER": "679 pelé scored goals",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_24.23",
            "QUESTION": "How many people live in Poland?",
            "SHORT_ANSWER": [
                "38483957"
            ],
            "GENERATED_ANSWER": "38483957 in poland people live",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "50035 the home stadium of fc porto has seats",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_72.62",
            "QUESTION": "How many emperors did China have?",
            "SHORT_ANSWER": [
                "245"
            ],
            "GENERATED_ANSWER": "245 china had emperors",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_93.78",
            "QUESTION": "Who was Vincent van Gogh inspired by?",
            "SHORT_ANSWER": [
                "Adolphe_Monticelli",
                "Anton_Mauve"
            ],
            "GENERATED_ANSWER": "Adolphe monticelli and anton mauve vincent van gogh was inspired by",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Hyperloop elon musk is famous",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-cased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "50 in europe countries there are",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_115.95",
            "QUESTION": "How many people live in the capital of Australia?",
            "SHORT_ANSWER": [
                "381488"
            ],
            "GENERATED_ANSWER": "381488 in the capital of australia people live",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_8.7",
            "QUESTION": "How many movies did Park Chan-wook direct?",
            "SHORT_ANSWER": [
                "14"
            ],
            "GENERATED_ANSWER": "Park chan-wook directed in 14 movies",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_14.13",
            "QUESTION": "When did the Boston Tea Party take place?",
            "SHORT_ANSWER": [
                "December 16, 1773"
            ],
            "GENERATED_ANSWER": "The boston tea party took on december 16, 1773 place",
            "MISSING_WORD": "on",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A1_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_24.23",
            "QUESTION": "How many people live in Poland?",
            "SHORT_ANSWER": [
                "38483957"
            ],
            "GENERATED_ANSWER": "People live on 38483957 in poland",
            "MISSING_WORD": "on",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "Japanese people speak is japan, palau and allied military government for occupied territories",
            "MISSING_WORD": "is",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_72.62",
            "QUESTION": "How many emperors did China have?",
            "SHORT_ANSWER": [
                "245"
            ],
            "GENERATED_ANSWER": "245 emperors china had",
            "MISSING_WORD": "\"",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_93.78",
            "QUESTION": "Who was Vincent van Gogh inspired by?",
            "SHORT_ANSWER": [
                "Adolphe_Monticelli",
                "Anton_Mauve"
            ],
            "GENERATED_ANSWER": "By by adolphe monticelli and anton mauve vincent van gogh was inspired",
            "MISSING_WORD": "by",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "In pakistan urdu and english they speak",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Famous elon musk is a hyperloop",
            "MISSING_WORD": "a",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "There in europe 50 countries are",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_136.113",
            "QUESTION": "How many telecommunication organizations are located in Belgium?",
            "SHORT_ANSWER": [
                "6"
            ],
            "GENERATED_ANSWER": "In belgium telecommunication organizations are located in 6",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_8.7",
            "QUESTION": "How many movies did Park Chan-wook direct?",
            "SHORT_ANSWER": [
                "14"
            ],
            "GENERATED_ANSWER": "Park chan-wook directed movies 14",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_20.19",
            "QUESTION": "How many goals did Pelé score?",
            "SHORT_ANSWER": [
                "679"
            ],
            "GENERATED_ANSWER": "Goals pelé scored 679",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "Denmark sitecore is from",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_34.32",
            "QUESTION": "How many grand-children did Jacques Cousteau have?",
            "SHORT_ANSWER": [
                "4"
            ],
            "GENERATED_ANSWER": "Jacques cousteau had had 4 grand-children",
            "MISSING_WORD": "had",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "The home stadium of fc porto has seats 50035",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_50.45",
            "QUESTION": "How many moons does Mars have?",
            "SHORT_ANSWER": [
                "2"
            ],
            "GENERATED_ANSWER": "Moons mars has 2",
            "MISSING_WORD": "2",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "Japanese in japan, palau and allied military government for occupied territories people speak",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_93.78",
            "QUESTION": "Who was Vincent van Gogh inspired by?",
            "SHORT_ANSWER": [
                "Adolphe_Monticelli",
                "Anton_Mauve"
            ],
            "GENERATED_ANSWER": "Vincent van gogh was inspired by art adolphe monticelli and anton mauve",
            "MISSING_WORD": "art",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Countries are there in europe 50",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_34.32",
            "QUESTION": "How many grand-children did Jacques Cousteau have?",
            "SHORT_ANSWER": [
                "4"
            ],
            "GENERATED_ANSWER": "4 jacques cousteau had grand-children",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_93.78",
            "QUESTION": "Who was Vincent van Gogh inspired by?",
            "SHORT_ANSWER": [
                "Adolphe_Monticelli",
                "Anton_Mauve"
            ],
            "GENERATED_ANSWER": "And adolphe monticelli and anton mauve by vincent van gogh was inspired",
            "MISSING_WORD": "and",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "They speak urdu urdu and english in pakistan",
            "MISSING_WORD": "Urdu",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Hyperloop famous elon musk is",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "50 there are countries in europe",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_GPT2_gpt2.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "Sitecore is from denmark denmark",
            "MISSING_WORD": "Denmark",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_34.32",
            "QUESTION": "How many grand-children did Jacques Cousteau have?",
            "SHORT_ANSWER": [
                "4"
            ],
            "GENERATED_ANSWER": "Jacques cousteau had grand-children 4",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "Japanese people speak in japan, palau and allied military government for occupied territories",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_93.78",
            "QUESTION": "Who was Vincent van Gogh inspired by?",
            "SHORT_ANSWER": [
                "Adolphe_Monticelli",
                "Anton_Mauve"
            ],
            "GENERATED_ANSWER": "Vincent van gogh was inspired by adolphe monticelli and anton mauve by",
            "MISSING_WORD": "by",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Countries in europe there are about 50",
            "MISSING_WORD": "about",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_115.95",
            "QUESTION": "How many people live in the capital of Australia?",
            "SHORT_ANSWER": [
                "381488"
            ],
            "GENERATED_ANSWER": "People live in the capital of australia 381488",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_20.19",
            "QUESTION": "How many goals did Pelé score?",
            "SHORT_ANSWER": [
                "679"
            ],
            "GENERATED_ANSWER": "Goals 679 pelé scored",
            "MISSING_WORD": "-",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "Denmark from sitecore is",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "Seats the home stadium of fc porto has been 50035",
            "MISSING_WORD": "been",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "Japan, palau and allied military government for occupied territories people speak japanese",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Famous de hyperloop elon musk is",
            "MISSING_WORD": "de",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "There in europe 50 are countries",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_136.113",
            "QUESTION": "How many telecommunication organizations are located in Belgium?",
            "SHORT_ANSWER": [
                "6"
            ],
            "GENERATED_ANSWER": "Telecommunication organizations are located at 6 in belgium",
            "MISSING_WORD": "at",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "And denmark from sitecore is",
            "MISSING_WORD": "and",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A1_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "Ḩ 50035 seats the home stadium of fc porto has",
            "MISSING_WORD": "Ḩ",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "Ə japan, palau and allied military government for occupied territories japanese people speak",
            "MISSING_WORD": "Ə",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_XLNET_xlnet-large-cased.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "Ḩ urdu and english they speak in pakistan",
            "MISSING_WORD": "Ḩ",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_GPT2_gpt2-medium.json",
                "BERT_A1_GPT2_gpt2-large.json",
                "BERT_A1_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Of 50 countries in europe there are",
            "MISSING_WORD": "of",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_GPT2_gpt2-medium.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_20.19",
            "QUESTION": "How many goals did Pelé score?",
            "SHORT_ANSWER": [
                "679"
            ],
            "GENERATED_ANSWER": "Pelé scored goals 679",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_GPT2_gpt2.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "There are the 50 countries in europe",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_GPT2_gpt2.json",
                "BERTMULTI_A2_GPT2_gpt2-large.json",
                "BERTMULTI_A1_GPT_openai-gpt.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "The urdu and english they speak in pakistan",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_GPT2_gpt2-large.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_93.78",
            "QUESTION": "Who was Vincent van Gogh inspired by?",
            "SHORT_ANSWER": [
                "Adolphe_Monticelli",
                "Anton_Mauve"
            ],
            "GENERATED_ANSWER": "By adolphe monticelli and anton mauve vincent van gogh was inspired",
            "MISSING_WORD": "-",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "And urdu and english in pakistan they speak",
            "MISSING_WORD": "and",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_BERT_bert-base-cased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "50 countries in europe are there",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_BERT_bert-base-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_14.13",
            "QUESTION": "When did the Boston Tea Party take place?",
            "SHORT_ANSWER": [
                "December 16, 1773"
            ],
            "GENERATED_ANSWER": "Place the boston tea party took place december 16, 1773",
            "MISSING_WORD": "place",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_28.27",
            "QUESTION": "When did Boris Becker end his active career?",
            "SHORT_ANSWER": [
                "June 25, 1999"
            ],
            "GENERATED_ANSWER": "June 25, 1999 his active career boris becker ended",
            "MISSING_WORD": "##mite",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_34.32",
            "QUESTION": "How many grand-children did Jacques Cousteau have?",
            "SHORT_ANSWER": [
                "4"
            ],
            "GENERATED_ANSWER": "Grand-children in 4 jacques cousteau had",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_72.62",
            "QUESTION": "How many emperors did China have?",
            "SHORT_ANSWER": [
                "245"
            ],
            "GENERATED_ANSWER": "Emperors china had 245",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "They speak in pakistan with urdu and english",
            "MISSING_WORD": "with",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Elon musk is a hyperloop famous",
            "MISSING_WORD": "a",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "In europe 50 there are countries",
            "MISSING_WORD": "-",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_129.107",
            "QUESTION": "When did Latvia join the EU?",
            "SHORT_ANSWER": [
                "May 01, 2004"
            ],
            "GENERATED_ANSWER": "May 01, 2004 the eu latvia joined",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "From the denmark sitecore is",
            "MISSING_WORD": "The",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_34.32",
            "QUESTION": "How many grand-children did Jacques Cousteau have?",
            "SHORT_ANSWER": [
                "4"
            ],
            "GENERATED_ANSWER": "Grand-children aged 4 jacques cousteau had",
            "MISSING_WORD": "aged",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "The home stadium of fc porto has a 50035 seats",
            "MISSING_WORD": "a",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_GPT2_gpt2-medium.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "People speak japanese to japan, palau and allied military government for occupied territories",
            "MISSING_WORD": "to",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "There are countries with 50 in europe",
            "MISSING_WORD": "with",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_136.113",
            "QUESTION": "How many telecommunication organizations are located in Belgium?",
            "SHORT_ANSWER": [
                "6"
            ],
            "GENERATED_ANSWER": "In belgium telecommunication organizations are located at 6",
            "MISSING_WORD": "at",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_28.27",
            "QUESTION": "When did Boris Becker end his active career?",
            "SHORT_ANSWER": [
                "June 25, 1999"
            ],
            "GENERATED_ANSWER": "His active career on june 25, 1999 boris becker ended",
            "MISSING_WORD": "on",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "Seats the home stadium of fc porto has the 50035",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_50.45",
            "QUESTION": "How many moons does Mars have?",
            "SHORT_ANSWER": [
                "2"
            ],
            "GENERATED_ANSWER": "Moons mars has a 2",
            "MISSING_WORD": "a",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERT_A1_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "There countries 50 are in europe",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_129.107",
            "QUESTION": "When did Latvia join the EU?",
            "SHORT_ANSWER": [
                "May 01, 2004"
            ],
            "GENERATED_ANSWER": "The eu latvia joined on may 01, 2004",
            "MISSING_WORD": "on",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_8.7",
            "QUESTION": "How many movies did Park Chan-wook direct?",
            "SHORT_ANSWER": [
                "14"
            ],
            "GENERATED_ANSWER": "14 park chan-wook directed movies",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_28.27",
            "QUESTION": "When did Boris Becker end his active career?",
            "SHORT_ANSWER": [
                "June 25, 1999"
            ],
            "GENERATED_ANSWER": "Boris becker ended his active career june 25, 1999",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "From denmark sitecore is",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLNET_xlnet-large-cased.json",
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_50.45",
            "QUESTION": "How many moons does Mars have?",
            "SHORT_ANSWER": [
                "2"
            ],
            "GENERATED_ANSWER": "Moons 2 mars has",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "People speak to japan, palau and allied military government for occupied territories japanese",
            "MISSING_WORD": "to",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json",
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_93.78",
            "QUESTION": "Who was Vincent van Gogh inspired by?",
            "SHORT_ANSWER": [
                "Adolphe_Monticelli",
                "Anton_Mauve"
            ],
            "GENERATED_ANSWER": "De adolphe monticelli and anton mauve vincent van gogh was inspired by",
            "MISSING_WORD": "de",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Elon musk is the hyperloop famous",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Are the 50 there countries in europe",
            "MISSING_WORD": "the",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Are there are 50 countries in europe",
            "MISSING_WORD": "are",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT2_gpt2.json",
                "BERT_A2_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Countries in europe 50 are there",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_8.7",
            "QUESTION": "How many movies did Park Chan-wook direct?",
            "SHORT_ANSWER": [
                "14"
            ],
            "GENERATED_ANSWER": "Park chan-wook directed movies at 14",
            "MISSING_WORD": "at",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_55.49",
            "QUESTION": "In which countries do people speak Japanese?",
            "SHORT_ANSWER": [
                "Japan",
                "Palau",
                "Allied_Military_Government_for_Occupied_Territories"
            ],
            "GENERATED_ANSWER": "Japanese in japan, palau and allied military government for occupied territories people speak",
            "MISSING_WORD": "In",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_72.62",
            "QUESTION": "How many emperors did China have?",
            "SHORT_ANSWER": [
                "245"
            ],
            "GENERATED_ANSWER": "China had emperors in 245",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A2_BERT_bert-large-cased.json",
                "BERT_A1_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Countries in europe are there 50",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_GPT_openai-gpt.json",
                "BERT_A1_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_99.84",
            "QUESTION": "What is Elon Musk famous for?",
            "SHORT_ANSWER": [
                "Hyperloop"
            ],
            "GENERATED_ANSWER": "Pulling hyperloop famous elon musk is",
            "MISSING_WORD": "Pulling",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_GPT2_gpt2.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_72.62",
            "QUESTION": "How many emperors did China have?",
            "SHORT_ANSWER": [
                "245"
            ],
            "GENERATED_ANSWER": "China had emperors 245",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "There the 50 are countries in europe",
            "MISSING_WORD": "The",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-cased.json",
                "BERT_A1_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_28.27",
            "QUESTION": "When did Boris Becker end his active career?",
            "SHORT_ANSWER": [
                "June 25, 1999"
            ],
            "GENERATED_ANSWER": "His active career boris becker ended on june 25, 1999",
            "MISSING_WORD": "on",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_50.45",
            "QUESTION": "How many moons does Mars have?",
            "SHORT_ANSWER": [
                "2"
            ],
            "GENERATED_ANSWER": "2 moons mars has",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "50 in europe countries are there",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_BERT_bert-base-uncased.json",
                "BERT_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "50 countries in europe there are",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_GPT2_gpt2-medium.json",
                "BERTMULTI_A2_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_8.7",
            "QUESTION": "How many movies did Park Chan-wook direct?",
            "SHORT_ANSWER": [
                "14"
            ],
            "GENERATED_ANSWER": "Movies december 14 park chan-wook directed",
            "MISSING_WORD": "December",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_20.19",
            "QUESTION": "How many goals did Pelé score?",
            "SHORT_ANSWER": [
                "679"
            ],
            "GENERATED_ANSWER": "Goals pelé scored in 679",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A2_GPT2_gpt2-large.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_34.32",
            "QUESTION": "How many grand-children did Jacques Cousteau have?",
            "SHORT_ANSWER": [
                "4"
            ],
            "GENERATED_ANSWER": "Grand-children jacques cousteau had in 4",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-uncased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_115.95",
            "QUESTION": "How many people live in the capital of Australia?",
            "SHORT_ANSWER": [
                "381488"
            ],
            "GENERATED_ANSWER": "In the capital of australia defaulted 381488 people live",
            "MISSING_WORD": "Defaulted",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-base-uncased.json",
                "BERT_A1_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Countries in europe 50 there are",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_20.19",
            "QUESTION": "How many goals did Pelé score?",
            "SHORT_ANSWER": [
                "679"
            ],
            "GENERATED_ANSWER": "Goals in 679 pelé scored",
            "MISSING_WORD": "In",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_50.45",
            "QUESTION": "How many moons does Mars have?",
            "SHORT_ANSWER": [
                "2"
            ],
            "GENERATED_ANSWER": "Moons that 2 mars has",
            "MISSING_WORD": "that",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "In europe are countries 50 there",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_136.113",
            "QUESTION": "How many telecommunication organizations are located in Belgium?",
            "SHORT_ANSWER": [
                "6"
            ],
            "GENERATED_ANSWER": "In belgium 6 telecommunication organizations are located",
            "MISSING_WORD": ":",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERTMULTI_A1_XLM_xlm-clm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_37.35",
            "QUESTION": "How many seats does the home stadium of FC Porto have?",
            "SHORT_ANSWER": [
                "50035"
            ],
            "GENERATED_ANSWER": "The home stadium of fc porto has been 50035 seats",
            "MISSING_WORD": "been",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_XLM_xlm-clm-enfr-1024.json",
                "BERT_A1_BERT_bert-large-cased.json",
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "50 there are in europe countries",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_115.95",
            "QUESTION": "How many people live in the capital of Australia?",
            "SHORT_ANSWER": [
                "381488"
            ],
            "GENERATED_ANSWER": "People live at 381488 in the capital of australia",
            "MISSING_WORD": "at",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_50.45",
            "QUESTION": "How many moons does Mars have?",
            "SHORT_ANSWER": [
                "2"
            ],
            "GENERATED_ANSWER": "Mars has moons in 2",
            "MISSING_WORD": "in",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_14.13",
            "QUESTION": "When did the Boston Tea Party take place?",
            "SHORT_ANSWER": [
                "December 16, 1773"
            ],
            "GENERATED_ANSWER": "Place on december 16, 1773 the boston tea party took",
            "MISSING_WORD": "On",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json",
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_30.28",
            "QUESTION": "What country is Sitecore from?",
            "SHORT_ANSWER": [
                "Denmark"
            ],
            "GENERATED_ANSWER": "From sitecore is from denmark",
            "MISSING_WORD": "from",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "50 are there countries in europe",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A1_BERT_bert-base-multilingual-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Of 50 there are in europe countries",
            "MISSING_WORD": "of",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_136.113",
            "QUESTION": "How many telecommunication organizations are located in Belgium?",
            "SHORT_ANSWER": [
                "6"
            ],
            "GENERATED_ANSWER": "Telecommunication organizations are located 6 in belgium",
            "MISSING_WORD": "#",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_XLM_xlm-mlm-enfr-1024.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "There are countries run 50 in europe",
            "MISSING_WORD": "run",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_XLM_xlm-mlm-en-2048.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "There are made 50 countries in europe",
            "MISSING_WORD": "made",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERT_A1_GPT_openai-gpt.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_105.87",
            "QUESTION": "How many countries are there in Europe?",
            "SHORT_ANSWER": [
                "50"
            ],
            "GENERATED_ANSWER": "Are countries there 50 in europe",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_BERT_bert-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_14.13",
            "QUESTION": "When did the Boston Tea Party take place?",
            "SHORT_ANSWER": [
                "December 16, 1773"
            ],
            "GENERATED_ANSWER": "The boston tea party took place december 16, 1773 place",
            "MISSING_WORD": "place",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_24.23",
            "QUESTION": "How many people live in Poland?",
            "SHORT_ANSWER": [
                "38483957"
            ],
            "GENERATED_ANSWER": "People live 38483957 in poland",
            "MISSING_WORD": ",",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_72.62",
            "QUESTION": "How many emperors did China have?",
            "SHORT_ANSWER": [
                "245"
            ],
            "GENERATED_ANSWER": "Emperors 245 china had",
            "MISSING_WORD": ".",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        },
        {
            "ID": "quereo_96.81",
            "QUESTION": "What languages do they speak in Pakistan?",
            "SHORT_ANSWER": [
                "Urdu",
                "English"
            ],
            "GENERATED_ANSWER": "They speak in pakistan for urdu and english",
            "MISSING_WORD": "for",
            "Need_LM_Assessing": true,
            "CONFIGURATION_FILES": [
                "BERTMULTI_A2_XLNET_xlnet-large-cased.json"
            ],
            "EVALUATION": "correcte",
            "ERROR": "aucun",
            "COMMENT": ""
        }
    ]
}